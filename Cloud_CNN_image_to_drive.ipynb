{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cloud_CNN_image-to-drive.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiwkaa7Sabp3mberd7bo+V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwDNlzsqK5vt"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------------------------------\n",
        "#Clouds.csv was created using Dr. Talaga's labeling program\n",
        "\n",
        "#Name: Tyler Gilbert\n",
        "#Class: CSCI 424\n",
        "#Date: 12/7/2021\n",
        "#Desc.: Program to split the images into different files on Google Drive\n",
        "\n",
        "#*I eventually mereged my training and validation folder, so my CNN did not use the validation folder\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "\n",
        "!pip install boto3\n",
        "!pip install Pillow \n",
        "\n",
        "import boto3\n",
        "\n",
        "# enter authentication credentials\n",
        "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAQLYZYAY2BX7ZTUUP', \n",
        "                          aws_secret_access_key= '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')\n",
        "\n",
        "bucket = s3.Bucket('uindy-weathercam')\n",
        "# Iterates through all the objects, if a string is in the key (filename)\n",
        "# put it into a list for analysis\n",
        "weather_file_names = []\n",
        "tweet_raw = []\n",
        "\n",
        "print(\"Loading files\", end='')\n",
        "for obj in bucket.objects.all():    # Investigate https://stackoverflow.com/questions/27292145/python-boto-list-contents-of-specific-dir-in-bucket\n",
        "\n",
        "  weather_file_names.append(obj.key)\n",
        "  #if '2020-12-01' in obj.key:  # As an example, load one day's tweets\n",
        "  #  key = obj.key\n",
        "  #  body = obj.get()['Body'].read()\n",
        "  #  tweet_raw.append( body )  # body will be binary data\n",
        "  #  print(\".\", end='')\n",
        "print(\"{} files scanned\".format(len(weather_file_names)))\n",
        "\n",
        "weather_file_names = sorted(weather_file_names)\n",
        "\n",
        "print(\"First 3 image files: {}\".format(weather_file_names[:3]))\n",
        "print(\"Last 3 image files: {}\".format(weather_file_names[-3:]))\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"First file {}\".format( datetime.fromtimestamp(int(weather_file_names[0].split('.')[0]) ) ))\n",
        "print(\"Last file {}\".format( datetime.fromtimestamp(int(weather_file_names[-1].split('.')[0]) ) ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(\"First file {}\".format( datetime.fromtimestamp(int(weather_file_names[0].split('.')[0]) ) ))\n",
        "print(\"Last file {}\".format( datetime.fromtimestamp(int(weather_file_names[-1].split('.')[0]) ) ))\n",
        "\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import pytz\n",
        "# Generate image names to include\n",
        "def convert_to_filename(unix_time):\n",
        "  print(unix_time)\n",
        "  rounded = int(int(unix_time / 60) * 60)\n",
        "  return str(rounded) + '.jpg'\n",
        "\n",
        "eastern = pytz.timezone('US/Eastern')\n",
        "files = []\n",
        "for i in range(10):\n",
        "  #             year   m,  d,  h,  m,  s, msec\n",
        "  dt = datetime(2019, 8, 2 + i, 10, 0, 0, tzinfo= eastern)\n",
        "  files.append(convert_to_filename(int(dt.timestamp())))\n",
        "print(files)"
      ],
      "metadata": {
        "id": "137W0G0nLEbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display # to display images\n",
        "\n",
        "def loadWeatherFile(filename):\n",
        "  import urllib.request\n",
        "  import io\n",
        "  from PIL import Image\n",
        "  url = \"http://uindy-weathercam.s3.us-east-2.amazonaws.com/\" + filename\n",
        "  fh = urllib.request.urlopen(url)\n",
        "  return Image.open(io.BytesIO(fh.read()))\n",
        "\n",
        "# # Display an image\n",
        "# im1 = loadWeatherFile('1635952080.jpg')\n",
        "# #display(im1)\n",
        "\n",
        "# # Based on a filename, which defines a time, download each image and display them\n",
        "# images = list(map(loadWeatherFile, files))\n",
        "# for im in images:\n",
        "#   display(im)"
      ],
      "metadata": {
        "id": "Qc1lSrZeLHVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('clouds.csv')\n",
        "df = df[[\"Cloud File\", \"Label\"]]\n",
        "\n",
        "#split into train, validation and testing\n",
        "\n",
        "df_train = df.iloc[:376,:]\n",
        "df_val = df.iloc[377:470,:]\n",
        "df_test = df.iloc[471:,:]\n",
        "\n",
        "#split each df into their cloud type\n",
        "\n",
        "df_train_cirrus = df_train[df_train['Label'] == 0.0]\n",
        "df_train_stratus = df_train[df_train['Label'] == 1.0]\n",
        "df_train_cumulus = df_train[df_train['Label'] == 2.0]\n",
        "df_train_other = df_train[df_train['Label'] == 3.0]\n",
        "\n",
        "df_val_cirrus = df_val[df_val['Label'] == 0.0]\n",
        "df_val_stratus = df_val[df_val['Label'] == 1.0]\n",
        "df_val_cumulus = df_val[df_val['Label'] == 2.0]\n",
        "df_val_other = df_val[df_val['Label'] == 3.0]\n",
        "\n",
        "df_test_cirrus = df_test[df_test['Label'] == 0.0]\n",
        "df_test_stratus = df_test[df_test['Label'] == 1.0]\n",
        "df_test_cumulus = df_test[df_test['Label'] == 2.0]\n",
        "df_test_other = df_test[df_test['Label'] == 3.0]\n",
        "\n",
        "#make lists of the file names for each cloud type \n",
        "\n",
        "cloud_files_train_cirrus = df_train_cirrus['Cloud File'].tolist()\n",
        "cloud_files_train_stratus = df_train_stratus['Cloud File'].tolist()\n",
        "cloud_files_train_cumulus = df_train_cumulus['Cloud File'].tolist()\n",
        "cloud_files_train_other = df_train_other['Cloud File'].tolist()\n",
        "\n",
        "cloud_files_val_cirrus = df_val_cirrus['Cloud File'].tolist()\n",
        "cloud_files_val_stratus = df_val_stratus['Cloud File'].tolist()\n",
        "cloud_files_val_cumulus = df_val_cumulus['Cloud File'].tolist()\n",
        "cloud_files_val_other = df_val_other['Cloud File'].tolist()\n",
        "\n",
        "cloud_files_test_cirrus = df_test_cirrus['Cloud File'].tolist()\n",
        "cloud_files_test_stratus = df_test_stratus['Cloud File'].tolist()\n",
        "cloud_files_test_cumulus = df_test_cumulus['Cloud File'].tolist()\n",
        "cloud_files_test_other = df_test_other['Cloud File'].tolist()"
      ],
      "metadata": {
        "id": "dyEDaWuULKG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the images into a list\n",
        "\n",
        "train_cirrus = list(map(loadWeatherFile, cloud_files_train_cirrus))\n",
        "train_stratus = list(map(loadWeatherFile, cloud_files_train_stratus))\n",
        "train_cumulus = list(map(loadWeatherFile, cloud_files_train_cumulus))\n",
        "train_other = list(map(loadWeatherFile, cloud_files_train_other))\n",
        "\n",
        "val_cirrus = list(map(loadWeatherFile, cloud_files_val_cirrus))\n",
        "val_stratus = list(map(loadWeatherFile, cloud_files_val_stratus))\n",
        "val_cumulus = list(map(loadWeatherFile, cloud_files_val_cumulus))\n",
        "val_other = list(map(loadWeatherFile, cloud_files_val_other))\n",
        "\n",
        "test_cirrus = list(map(loadWeatherFile, cloud_files_test_cirrus))\n",
        "test_stratus = list(map(loadWeatherFile, cloud_files_test_stratus))\n",
        "test_cumulus = list(map(loadWeatherFile, cloud_files_test_cumulus))\n",
        "test_other = list(map(loadWeatherFile, cloud_files_test_other))"
      ],
      "metadata": {
        "id": "cXnnn64HLNgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#edit and send the images into their folder\n",
        "\n",
        "#folders need to be made in Google Drive, and then mount Google Drive in Colab\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "for im,i in zip(train_cirrus,cloud_files_train_cirrus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/train/cirrus/\" + i)\n",
        "for im,i in zip(train_stratus,cloud_files_train_stratus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/train/stratus/\" + i)\n",
        "for im,i in zip(train_cumulus,cloud_files_train_cumulus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/train/cumulus/\" + i)\n",
        "for im,i in zip(train_other,cloud_files_train_other):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  display(im)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/train/other/\" + i)\n",
        "\n",
        "\n",
        "for im,i in zip(val_cirrus,cloud_files_val_cirrus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/val/cirrus/\" + i)\n",
        "for im,i in zip(val_stratus,cloud_files_val_stratus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/val/stratus/\" + i)\n",
        "for im,i in zip(val_cumulus,cloud_files_val_cumulus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/val/cumulus/\" + i)\n",
        "for im,i in zip(val_other,cloud_files_val_other):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/val/other/\" + i)\n",
        "\n",
        "\n",
        "for im,i in zip(test_cirrus,cloud_files_test_cirrus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/test/cirrus/\" + i)\n",
        "for im,i in zip(test_stratus,cloud_files_test_stratus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/test/stratus/\" + i)\n",
        "for im,i in zip(test_cumulus,cloud_files_test_cumulus):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/test/cumulus/\" + i)\n",
        "for im,i in zip(test_other,cloud_files_test_other):\n",
        "  baseheight = 224\n",
        "  width = 224\n",
        "  im = im.resize((width, baseheight), Image.ANTIALIAS)\n",
        "  im.save(\"/content/drive/MyDrive/CloudImages/test/other/\" + i)"
      ],
      "metadata": {
        "id": "8Bnu0kXZLSRD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}